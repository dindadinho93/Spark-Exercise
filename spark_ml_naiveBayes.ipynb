{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification  import NaiveBayes\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, VectorIndexer\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('SparkNB').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NomorPasien: double (nullable = true)\n",
      " |-- NomorAppointment: integer (nullable = true)\n",
      " |-- JenisKelamin: string (nullable = true)\n",
      " |-- TanggalPembuatan: timestamp (nullable = true)\n",
      " |-- TanggalAppointment: timestamp (nullable = true)\n",
      " |-- Umur: integer (nullable = true)\n",
      " |-- Daerah: string (nullable = true)\n",
      " |-- Beasiswa: integer (nullable = true)\n",
      " |-- DarahTinggi: integer (nullable = true)\n",
      " |-- Diabetes: integer (nullable = true)\n",
      " |-- Alkohol: integer (nullable = true)\n",
      " |-- Disabled: integer (nullable = true)\n",
      " |-- SMS_received: integer (nullable = true)\n",
      " |-- No-show: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('D:/KULIAH/no_show_appointments.csv', header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+------------+-------------------+-------------------+----+----------------+--------+-----------+--------+-------+--------+------------+-------+------+-----+\n",
      "|NomorPasien|NomorAppointment|JenisKelamin|   TanggalPembuatan| TanggalAppointment|Umur|          Daerah|Beasiswa|DarahTinggi|Diabetes|Alkohol|Disabled|SMS_received|No-show|Gender|Label|\n",
      "+-----------+----------------+------------+-------------------+-------------------+----+----------------+--------+-----------+--------+-------+--------+------------+-------+------+-----+\n",
      "| 2.14311E13|         5611376|           F|2016-04-25 14:08:41|2016-05-25 07:00:00|  43|     Bidara Cina|       0|          0|       0|      0|       0|           1|     No|   0.0|  0.0|\n",
      "| 2.83935E13|         5629135|           M|2016-04-27 19:50:39|2016-04-29 07:00:00|  78| Harapan Mulia  |       0|          1|       1|      0|       0|           0|     No|   1.0|  0.0|\n",
      "| 3.48758E13|         5686183|           M|2016-05-11 19:18:24|2016-05-17 07:00:00|  58|       Cililitan|       0|          1|       0|      0|       0|           0|     No|   1.0|  0.0|\n",
      "| 8.35673E13|         5729853|           F|2016-05-24 14:54:37|2016-05-24 07:00:00|  22|    Cempaka Baru|       0|          0|       0|      0|       0|           0|     No|   0.0|  0.0|\n",
      "| 9.18688E14|         5690145|           F|2016-05-12 16:34:57|2016-05-12 07:00:00|  30|       Cijantung|       0|          0|       0|      0|       0|           0|     No|   0.0|  0.0|\n",
      "+-----------+----------------+------------+-------------------+-------------------+----+----------------+--------+-----------+--------+-------+--------+------------+-------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndex = [StringIndexer(inputCol='JenisKelamin', outputCol='Gender'), StringIndexer(inputCol='No-show', outputCol='Label')]\n",
    "pipeline = Pipeline(stages=stringIndex) \n",
    "\n",
    "df = pipeline.fit(df).transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureAssembler = VectorAssembler(inputCols=['DarahTinggi','Diabetes','Alkohol','SMS_received','Gender'], outputCol='Features')\n",
    "df2 = featureAssembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Features|Label|\n",
      "+--------------------+-----+\n",
      "|       (5,[3],[1.0])|  0.0|\n",
      "|[1.0,1.0,0.0,0.0,...|  0.0|\n",
      "| (5,[0,4],[1.0,1.0])|  0.0|\n",
      "|           (5,[],[])|  0.0|\n",
      "|           (5,[],[])|  0.0|\n",
      "| (5,[3,4],[1.0,1.0])|  1.0|\n",
      "|       (5,[3],[1.0])|  0.0|\n",
      "|       (5,[0],[1.0])|  0.0|\n",
      "|       (5,[2],[1.0])|  0.0|\n",
      "|           (5,[],[])|  0.0|\n",
      "|           (5,[],[])|  0.0|\n",
      "|       (5,[0],[1.0])|  0.0|\n",
      "|       (5,[4],[1.0])|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 13 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df2.select(['Features','Label'])\n",
    "df3.show(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            Features|Label|              Scaler|\n",
      "+--------------------+-----+--------------------+\n",
      "|       (5,[3],[1.0])|  0.0|(5,[3],[2.1419113...|\n",
      "|[1.0,1.0,0.0,0.0,...|  0.0|[2.51305942778134...|\n",
      "| (5,[0,4],[1.0,1.0])|  0.0|(5,[0,4],[2.51305...|\n",
      "|           (5,[],[])|  0.0|           (5,[],[])|\n",
      "|           (5,[],[])|  0.0|           (5,[],[])|\n",
      "| (5,[3,4],[1.0,1.0])|  1.0|(5,[3,4],[2.14191...|\n",
      "|       (5,[3],[1.0])|  0.0|(5,[3],[2.1419113...|\n",
      "|       (5,[0],[1.0])|  0.0|(5,[0],[2.5130594...|\n",
      "|       (5,[2],[1.0])|  0.0|(5,[2],[5.8246018...|\n",
      "|           (5,[],[])|  0.0|           (5,[],[])|\n",
      "|           (5,[],[])|  0.0|           (5,[],[])|\n",
      "|       (5,[0],[1.0])|  0.0|(5,[0],[2.5130594...|\n",
      "|       (5,[4],[1.0])|  1.0|(5,[4],[2.0965282...|\n",
      "| (5,[3,4],[1.0,1.0])|  0.0|(5,[3,4],[2.14191...|\n",
      "| (5,[0,4],[1.0,1.0])|  0.0|(5,[0,4],[2.51305...|\n",
      "|           (5,[],[])|  1.0|           (5,[],[])|\n",
      "|       (5,[4],[1.0])|  0.0|(5,[4],[2.0965282...|\n",
      "| (5,[3,4],[1.0,1.0])|  0.0|(5,[3,4],[2.14191...|\n",
      "|           (5,[],[])|  0.0|           (5,[],[])|\n",
      "|       (5,[4],[1.0])|  0.0|(5,[4],[2.0965282...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(inputCol='Features', outputCol='Scaler', withStd=True, withMean=False)\n",
    "df3 = scaler.fit(df3).transform(df3)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "trainingData, testData = df3.randomSplit([0.7, 0.3], seed=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(featuresCol='Scaler', labelCol='Label', smoothing=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbmodel = nb.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---------+--------------------+--------------------+----------+\n",
      "| Features|Label|   Scaler|       rawPrediction|         probability|prediction|\n",
      "+---------+-----+---------+--------------------+--------------------+----------+\n",
      "|(5,[],[])|  0.0|(5,[],[])|[-0.2250571610265...|[0.79847057605713...|       0.0|\n",
      "|(5,[],[])|  0.0|(5,[],[])|[-0.2250571610265...|[0.79847057605713...|       0.0|\n",
      "|(5,[],[])|  0.0|(5,[],[])|[-0.2250571610265...|[0.79847057605713...|       0.0|\n",
      "|(5,[],[])|  0.0|(5,[],[])|[-0.2250571610265...|[0.79847057605713...|       0.0|\n",
      "|(5,[],[])|  0.0|(5,[],[])|[-0.2250571610265...|[0.79847057605713...|       0.0|\n",
      "+---------+-----+---------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = nbmodel.transform(testData)\n",
    "predictions.show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.487549315355889\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Label\", rawPredictionCol='rawPrediction')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes with Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbparamGrid = (ParamGridBuilder()\n",
    "               .addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "               .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "nbcv = CrossValidator(estimator = nb,\n",
    "                      estimatorParamMaps = nbparamGrid,\n",
    "                      evaluator = nbevaluator,\n",
    "                      numFolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidatorModel_3d13b2446767\n"
     ]
    }
   ],
   "source": [
    "nbcvModel = nbcv.fit(trainingData)\n",
    "print(nbcvModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbpredictions = nbcvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.487549315355889\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(nbpredictions)\n",
    "#f1 = evaluator.setMetricName('f1').evaluate(predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "#print('F1:', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
